---
title: "Data Visualization (KEEP)"
author: "Judah Hsu"
date: "2023-06-08"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

### Success\~Mouse Bar Graph & Contingency Table (KEEP?) DONE

#KEEP/EDIT although number of trials is different for each mouse, we're
primarily concerned with proportions and comparison within a mouse. So,
the contingency table covers proportions though it might be better to
change the graph to show proportions.

Intuition: The primary point of this graph and contingency table is too
check homogeneity across mice by looking at the probability of success
between the different mice. To do so, I built a bar graph of the number
of successful vs failed trials for each mouse, as well as a contingency
table to specify the proportions.

Result: In the bar graph and contingency table, we see that Lederberg
actually had the highest proportion of successes (0.76) while the other
3 mice had proportions of success spanning 0.64-0.68. Though it's also
important to note that Lederberg had the most trials (so Lederberg
could've learned the most), it's clear to see that the proportion of
success is different with Lederberg compared to the other three mice.

```{r, include=TRUE}
library(tidyverse)
session=list()

name_list <- c()

for(i in 1:18){
  session[[i]]=readRDS(paste(("/Users/judahhsu/Desktop/classes/STA 141A/sessions/session"),i,'.rds',sep=''))
  #print(session[[i]]$mouse_name)
  #print(session[[i]]$date_exp)
  name_list <- c(name_list, session[[i]]$mouse_name)
}
#Get different names for data frame
name_list <- name_list %>% unique() 
name_list

#Create empty dataframe for each mouse, replacing each NA value with 0
success.vals <- data.frame(matrix(ncol=4, nrow=2))
colnames(success.vals) = name_list 
rownames(success.vals) = c("Failures", "Successes")
success.vals[is.na(success.vals)] <- 0

for(i in 1:18){
  #obtain data frame of success/failure for given name
  df.success <- session[[i]]$feedback_type %>% data.frame()
  df.success <- df.success %>% count(session[[i]]$feedback_type==1)
  success.nums <- df.success$n #success.nums[[1]] == failure
  #Add success & failure counts to mice names
  success.vals[[session[[i]]$mouse_name]][[1]] <- success.vals[[session[[i]]$mouse_name]][[1]] + success.nums[[1]]
  success.vals[[session[[i]]$mouse_name]][[2]] <- success.vals[[session[[i]]$mouse_name]][[2]] + success.nums[[2]]
}

#convert success.vals to more readable dataframe
success.vals <- data.frame(t(success.vals))
  
data <- data.frame(
  Names = name_list,
  Failures = success.vals$Failures,
  Successes = success.vals$Successes
)


#Create contingency table
contingency_table <- data.frame(
  names = name_list,
  Failures = success.vals$Failures / (success.vals$Failures + success.vals$Successes),
  Successes = success.vals$Successes / (success.vals$Failures + success.vals$Successes)
)
contingency_table

#Create new dataset of more specific values
data.long <- data %>% pivot_longer(cols = c(Failures, Successes), names_to = "Category", values_to = "Counts")

#Plot
plot.long <- data.long %>% ggplot(aes(x=Names, y=Counts, fill=Category)) +
  geom_bar(stat="identity", position="dodge") +
  labs(x="Names", y="Counts") 

#ggsave("fig_2.3.png", plot.long)

print(plot.long)
#"/Users/judahhsu/Desktop/classes/STA 141A/sessions/session"
```

### Success\~Session DONE

#KEEP Maybe you can add smth on but i think the method is good and the
visualization is fine

Intuition: Another thing we want to examine is homogeneity across each
session. If a mouse learns after many trials, does it retain that
learning through the following sessions? In order to do so, we broadly
find the proportions of successes per trial and map the proportions of
the successes with the dates of the sessions (per mouse). In doing so,
we'll be able to see if the probability of success tends to increase
over time.

Result: Looking at the graphs, there doesn't seem to be a clear trend.
For one, there aren't that many data points to begin with but looking at
the graphs, the points seem to oscillate. Even though the overall trend
is positive for each, sessions will increase or decrease their
probability of success relatively randomly. This could be a result of
variation that comes from not enough data points but currently, it does
not seem like probability of success increases over sessions. The only
mouse with consistently increasing success probability is Cori but even
then, the increase is not particularly significant.

```{r}
#Get a list of proportions, corresponding dates, and mice
library(gridExtra)
list.prop <- c()
list.names <- c()
list.dates <- c()

for(i in 1:18){
  df.temp <- session[[i]]$feedback_type %>% data.frame()
  df.temp <- df.temp %>% count(session[[i]]$feedback_type == 1)
  list.prop <- c(list.prop, df.temp$n[[2]] / (df.temp$n[[1]] + df.temp$n[[2]]))
  list.names <- c(list.names, session[[i]]$mouse_name)
  list.dates <- c(list.dates, session[[i]]$date_exp)
}
df.session.success <- data.frame(`Prob of Success` = list.prop,
                                 "Names" = list.names,
                                 "Dates" = list.dates)
df.session.success$Dates <- as.Date(df.session.success$Dates)
df.session.success <- df.session.success[order(df.session.success$Dates),]

print(df.session.success)

success.cori <- df.session.success %>% filter(Names=="Cori")
success.hench <- df.session.success %>% filter(Names=="Hench")
success.forss <- df.session.success %>% filter(Names=="Forssmann")
success.led <- df.session.success %>% filter(Names=="Lederberg")

plot.cori <- success.cori %>% ggplot() +
  geom_point(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_line(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_text(mapping = aes(x=Dates, y=Prob.of.Success, label=format(Dates, "%Y-%m-%d")), vjust = -1.5,size = 2, color='red')  +
  scale_y_continuous(limits=c(0.5, 1), breaks=seq(0.5, 1, 0.05)) +
  geom_smooth(mapping=aes(x=Dates, y=Prob.of.Success), se=FALSE, method='lm')

plot.hench<- success.hench %>% ggplot() +
  geom_point(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_line(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_text(mapping = aes(x=Dates, y=Prob.of.Success, label=format(Dates, "%Y-%m-%d")), vjust = -1.5,size = 2, color='red') +
  scale_y_continuous(limits=c(0.5, 1), breaks=seq(0.5, 1, 0.05)) +
  geom_smooth(mapping=aes(x=Dates, y=Prob.of.Success), se=FALSE, method='lm')

plot.forss <- success.forss %>% ggplot() +
  geom_point(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_line(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_text(mapping = aes(x=Dates, y=Prob.of.Success, label=format(Dates, "%Y-%m-%d")), vjust = -1.5,size = 2, color='red') +
  scale_y_continuous(limits=c(0.5, 1), breaks=seq(0.5, 1, 0.05)) +
  geom_smooth(mapping=aes(x=Dates, y=Prob.of.Success), se=FALSE, method='lm')

plot.led <- success.led %>%ggplot(aes(x=Dates, y=Prob.of.Success)) +
  geom_point(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_line(mapping=aes(x=Dates, y=Prob.of.Success)) +
  geom_text(mapping = aes(x=Dates, y=Prob.of.Success, label=format(Dates, "%Y-%m-%d")), vjust = -1.5,size = 2, color='red') +
  scale_y_continuous(limits=c(0.5, 1), breaks=seq(0.5, 1, 0.05)) +
  geom_smooth(mapping=aes(x=Dates, y=Prob.of.Success), se=FALSE, method='lm')
  
grid.arrange(plot.cori, plot.hench, plot.forss, plot.led, ncol=4)

ggsave("fig_2.4.cori.png", plot.cori)
ggsave("fig_2.4.hench.png", plot.hench)
ggsave("fig_2.4.forss.png", plot.forss)
ggsave("fig_2.4.led.png", plot.led)
```

### Success\~Trial DONE

#EDIT This is the first big edit, we want to do a time series with the
actual time

#Keep now?

Intuition: We want to look into changes across trials because it's
possible that mice might learn a lot more quickly over more trials or
they might be less incentivised to make the right decision as their
thirst is satisfied. In order to look at the probability of success for
trial 1, we find the proportion of success for trial 1 across all 18
sessions. Then, we do this for the first 114 trials. Because session 1
is limited to 114 trials, we start by looking solely at the first 114
trials.

Result: Looking at the time series for the first 114 trials, there
doesn't appear to be much of a trend. We do notice that there's a bit of
a dip towards the end but there's also a bit of an increase in the
middle. So, completely ignoring session 1, we look at the rest of the 17
trials and look at the first 216 trials. Using that graph, we notice a
much more noticeable dip. Using 17, instead of 18 trials, the line
became more smoothed for the first 180-or-so trials but then noticeably
dipped after. From this, it appears that for some reason, the
probability of success for a mouse decreases noticeably at 200 trials.

Probability of success, across sessions, over the first 114 trials

```{r}

#lets use bins for the times to find probability of success because this is mad
#First try bins of 10 without rescaling
list.time <- c()
list.success <- c()
for (s in 1:length(session)){
  #Go through each session
  for (i in 1:length(session[[s]]$time)){
    #Go through each trial
    #list.time <- c(list.time, session[[s]]$time[[i]][1] - session[[s]]$time[[1]][1]) 
    list.time <- c(list.time, session[[s]]$time[[i]][1])
  }
  list.success <- c(list.success, session[[s]]$feedback_type)
}
time.df <- data.frame(time=list.time, success=list.success)

list.timebins <- seq(30, 1780, by=10) #Bins by 1 is too small in my opinion
list.propbins <- c()
for(b in 1:length(list.timebins)){
  #For each time bin, find the number of trials in that time bin, and the number of successes
  #Get the rows of interest
  bin.df <- time.df %>% filter(time > list.timebins[b] & time < list.timebins[b+1]) #Get rows within time bin
  n <- length(bin.df$time)
  success.df <- bin.df %>% filter(success==1)
  s <- length(success.df$success)
  list.propbins <- c(list.propbins, s/n)
}

binsuccess.df <- data.frame(prop = list.propbins, time.bins = list.timebins)
binsuccess.df %>% ggplot(aes(x=time.bins,y=prop)) +
  geom_bar(stat='identity') +
  geom_smooth(se=FALSE, color='red')
  
#Something important to note is that there are very even probabilities towards the end, indicating that maybe there's less values
#Justify the loess method
```

```{r}
#Obtain the number of trials in each session
trials.num <- c()
for(i in 1:18) {
  trials.num <- c(trials.num, length(session[[i]]$feedback_type))
}

#Obtain the least amount of trials each session has done
trials.num.min <- min(trials.num)

#Initialize probability vector for those trials
prob.success <- c()

#Get vector for probability of success
for(n in 1:trials.num.min){
  feedback.pos <- 0
  feedback.neg <- 0
  #Get number of pos & neg feedbacks across sessions for that trial
  for(t in 1:18){ 
    if(session[[t]]$feedback_type[n] > 0){
      feedback.pos <- feedback.pos + 1
    } else{
      feedback.neg <- feedback.neg + 1
    }
  }
  prob.success <-c(prob.success, feedback.pos/(feedback.pos + feedback.neg))
}

#Create data frame of trials and their respective probabilites of success
data.success <- data.frame(Trial=1:length(prob.success), Values = prob.success)

#Plot
data.success %>% ggplot(aes(x=Trial, y=Values)) +
  geom_line() +
  geom_smooth(se=FALSE) +
  xlab("Trial Number") +
  ylab("Success Probabilities") +
  ggtitle("Probability of success, across sessions, over trials")
```

Probability of success, across sessions, over the first 200 trials

```{r}

#Obtain the number of trials in each session, excluding 1st trial (previous minimum trials)
trials.num <- c()
for(i in 2:18){
  trials.num <- c(trials.num, length(session[[i]]$feedback_type))
}

#Obtain least number of trials
trials.num.min <- min(trials.num)

#Initialize probability vector for those trials
prob.success <- c()

#Get vector for probability of success
for(n in 1:trials.num.min){
  feedback.pos <- 0
  feedback.neg <- 0
  #Get number of pos & neg feedbacks across sessions for that trial
  for(t in 2:18){ 
    if(session[[t]]$feedback_type[n] > 0){
      feedback.pos <- feedback.pos + 1
    } else{
      feedback.neg <- feedback.neg + 1
    }
  }
  prob.success <-c(prob.success, feedback.pos/(feedback.pos + feedback.neg))
}

#Create data frame for trials and their respective probabilities of successes
data.success <- data.frame(Trial=1:length(prob.success), Values = prob.success)

#Plot
data.success %>% ggplot(aes(x=Trial, y=Values)) +
  geom_line() +
  geom_smooth(se=FALSE) +
  xlab("Trial Number") +
  ylab("Success Probabilities") +
  ggtitle("Probability of success, across sessions, over trials")
```

### Success \~ neuron firing in specific brain areas USED

#KEEP

Intuition: In order to determine whether neuron firing in certain parts
of the brain is correlated to success, we build 2 heat maps for each
session- one for trials resulting in failure and another for trials
resulting in success. Each heat map will have time bins as the columns,
as well as brain areas as the rows. In order to determine whether
different brain areas have different effects, we condense each session's
neuron spikes into an aggregate form, based on brain area and time bin.

Result: Looking solely at the color distributions of the neurons in the
brain areas, it seems like brain areas (at least the aggregate spikes)
don't seem to make a big difference in failure and success. The color
distributions are generally the same for the failure & success heat maps
per session. So, this indicates to us the aggregate amount of spikes in
a brain area cannot be used to predict success or failure since both
successful and failed trials include the same proportion of neural
activity in the same brain areas. If anything, we notice that the heat
maps for successful trials have noticeably more neuron spikes than heat
maps for failure trials. Furthermore, we notice that for session 17 who
has a proportion of success of 0.83 (the highest recorded), the "Root"
brain area is where a majority of the neuron firing occurred. However,
session 6 which had the second-lowest proportion of success (0.61), also
recorded most of the neuron firing occurring in the "Root" brain area.
In this way, brain areas on their own don't seem to directly correlate
to probabilities of success either.

However, considering that for most mice, the proportions of successful
trials they have are well over 0.6, it would not be appropriate to
relate success to aggregate number of neuron spikes. #Probably turn it
into average by the number of times the brain area appears in the
session (number of neurons for that brain area)

```{r}
library(reshape2)
library(tidyverse)

#For creating the matrix of neuron firing brain areas in a trial
create_trial_matrix <- function(sesh, trial.num) { #sesh = session[[1]], trial.num=1
  #Initialize matrix
  areas.num <- sesh$brain_area %>% unique() %>% length()# different sessions have different brain areas measured
  matrix.area.trial <- matrix(nrow = areas.num, ncol=40)
  matrix.area.trial[is.na(matrix.area.trial)] <- 0

  #Create list containing unique brain area names
  areas.list <- unique(sesh$brain_area)

  #Loop through trial in a session to add to previous vector in regards to firing at a certain time bin, in a certain brain    area
  for (i in 1:nrow(sesh$spks[[trial.num]])){
    #This will loop for every row
  
    #Find the index in areas.list of the current neuron's brain area so the value can be added to the original matrix
    area.index <- which(areas.list == sesh$brain_area[[i]])
    for (j in 1:ncol(sesh$spks[[trial.num]])) {
      #This will loop for ever column in that row s.t. j represents the column number

      #Add to the matrix the value found at the current neuron, based on its brain area and time bin
      matrix.area.trial[area.index,j] <- matrix.area.trial[area.index,j] + sesh$spks[[trial.num]][i,j]
    }
  }
  return(matrix.area.trial)
}

#Code to turn matrix into heatmap, specifically for this scenario
matrix_to_heatmap <- function(mx, areas, check, sesh.num) {
  #HERE is where i can alter it. Given a session number, how do I find the average value for a brain area
  sesh.name <- session[[sesh.num]]$mouse_name
  df <- melt(mx)
  df$Var1 <- factor(df$Var1, levels = 1:length(areas), labels=areas)
  
  #TURN the values into averages spikes for a brain area's 
  #I might've been able to skip the for loop by just putting "df$Var1" instead of "df$Var1[ba]" where i get the total number of brain areas to divide by
  brain.areas.temp <- session[[sesh.num]]$brain_area %>% table()
  for(ba in 1:length(df$Var1)){
    df$value[ba] <- df$value[ba] / as.numeric(brain.areas.temp[df$Var1[ba]])
  }
  
  #TURN the values into average spikes per trial
  if(check == 1){
    num.trials <- as.numeric((session[[sesh.num]]$feedback_type %>% table())["1"]) #Gets the number of success trials
    for (ba in 1:length(df$Var1)){
      df$value[ba] <- df$value[ba] / num.trials
    }
  }
  else{
    num.trials <- as.numeric((session[[sesh.num]]$feedback_type %>% table())["-1"]) #Gets the number of success trials
    for (ba in 1:length(df$Var1)){
      df$value[ba] <- df$value[ba] / num.trials
    }
  }
  
  #Separate heat maps for success & failure
  if(check == 1){
    title.heat <- paste("Success Heatmap for", sesh.name, ": session", sesh.num)
  }
  else {
    title.heat <- paste("Failure Heatmap for", sesh.name, ": session", sesh.num)
  }
  heatmap_plot <- df %>% ggplot(aes(x=Var2, y=Var1, fill=value)) +
    geom_tile() + 
    scale_fill_gradient(low='white', high='red') + 
    labs(x='Time Bins', y = 'Brain Areas', title = title.heat)
  print(heatmap_plot)
}

#For getting aggregate matrix in a session
create_session_heatmap <- function(sesh) { #sesh == session[[1]]
  areas.list <- unique(sesh$brain_area)
  
  #Initialize matrices for failure and success in session
  areas.num <- sesh$brain_area %>% unique() %>% length()# different sessions have different brain areas measured
  matrix.agg.success <- matrix(nrow = areas.num, ncol=40)
  matrix.agg.success[is.na(matrix.agg.success)] <- 0
  matrix.agg.fail <- matrix(nrow = areas.num, ncol=40)
  matrix.agg.fail[is.na(matrix.agg.fail)] <- 0
  length(sesh$feedback_type)

  #add values to success and failure matrices
  for(s in 1:length(sesh$feedback_type)){
    if(sesh$feedback_type[[s]] == 1){
      matrix.agg.success <- matrix.agg.success + create_trial_matrix(sesh, s)
    }
    else{
      matrix.agg.fail <- matrix.agg.fail + create_trial_matrix(sesh, s)
    }
  }
  
  matrix.agg <- list()
  matrix.agg[[1]] <- matrix.agg.success
  matrix.agg[[2]] <- matrix.agg.fail
  
  #par(mfrow=c(1,2))
  #matrix_to_heatmap(matrix.agg.success, areas.list)
  #matrix_to_heatmap(matrix.agg.fail, areas.list)
  
  return(matrix.agg)
}

#Loop through the sessions
#Still need to add formatting
for (n in 1:length(session)) {
  areas.list <- unique(session[[n]]$brain_area)
  matrix.agg <- create_session_heatmap(session[[n]])
  matrix_to_heatmap(matrix.agg[[1]], areas.list, 1, n)
  matrix_to_heatmap(matrix.agg[[2]], areas.list, 2, n)
}

#Probability table
print(cbind("Session #" = seq(1,18,1),df.session.success))
#Most successful sessions: 7, 13, 17, 18
```

### Success \~ Contrasts

#KEEP

Intuition: Across each session, we want to see if the difference between
the left & right contrasts on the screen affect success. For example, if
there's a bigger contrast between the left and right sides of a screen,
it's likely that the mouse will be better able to notice the difference.
So, for each session, we make bar charts for each difference in
contrast(-1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1), as well as the
absolute differences. To find contrast, we subtract the right contrast
from the left, such that negative contrasts indicate that the right
contrast is greater. In doing so, we'll be able to see if success is
more likely for greater contrasts/greater absolute contrasts. From
there, we create segmented bar graphs for each session, indicating the
number of successes and failures. Since there's generally more successes
than failures, however, we will look at the proportions of successes at
each contrast, rather than the counts.

Result: Looking at the bar graphs for absolute differences, there
doesn't seem to be a clear trend. In fact, the proportion of successes
across contrasts seems to be relatively constant, indicating that
contrast levels don't affect the probability of success. Looking at pure
contrasts, contrast levels still don't seem to affect success. For some
mice, like Forssman, they do better when the right contrast is greater
during multiple trials. However, this isn't fully consistent nor
obvious. So, contrast does not seem to affect success.

```{r}
library(tidyverse)
library(ggplot2)
library(gridExtra)

create_count_contrast_bar <- function(n){
  diff <- (session[[n]]$contrast_left - session[[n]]$contrast_right)
  diff <- data.frame(Contrast = as.numeric(diff), Feedback = as.factor(session[[n]]$feedback_type))
  diff <- diff %>% arrange(Contrast)
  plot.bar <- diff %>% ggplot() +
    geom_bar(mapping=aes(x=Contrast, fill=Feedback)) +
    labs(title = paste("Session ", n, ",", session[[n]]$mouse_name))
  return(plot.bar)
}

create_prop_contrast_bar <- function(n, abs){
  #Create data frame of contrasts
  if(abs == 0){
   diff <- (session[[n]]$contrast_left - session[[n]]$contrast_right) 
  }
  else{
    diff <- abs(session[[n]]$contrast_left - session[[n]]$contrast_right)
  }
  diff <- data.frame(Contrast = as.numeric(diff), Feedback = as.factor(session[[n]]$feedback_type))
  diff <- diff %>% arrange(Contrast)
  #Group data frame  to find counts for each
  diff <- diff %>% group_by(Contrast, Feedback) %>% count()

  #Reshape data frame to add proportions instead of counts
  props <-c()
  for (i in 1:length(diff$Contrast)){
    contrast.vals.temp <- diff %>% filter(Contrast == diff$Contrast[i])
    total.temp <- sum(contrast.vals.temp$n)
    props <- c(props, diff$n[i]/total.temp)
  }
  diff<-cbind(diff, props=props)
  #Plot
  plot.bar <- diff %>% ggplot(aes(x=Contrast,y=props)) +
    geom_bar(stat='identity', mapping=aes(fill=Feedback)) +
    labs(title = paste("Session ", n, ",", session[[n]]$mouse_name))
  return(plot.bar)
}

print_count_contrasts <- function(){
  cori.1 <- create_count_contrast_bar(1)
  cori.2 <- create_count_contrast_bar(2)
  cori.3 <- create_count_contrast_bar(3)
  forss.4 <- create_count_contrast_bar(4)
  forss.5 <- create_count_contrast_bar(5)
  forss.6 <- create_count_contrast_bar(6)
  forss.7 <- create_count_contrast_bar(7)
  hench.8 <- create_count_contrast_bar(8)
  hench.9 <- create_count_contrast_bar(9)
  hench.10 <- create_count_contrast_bar(10)
  hench.11 <- create_count_contrast_bar(11)
  led.12 <- create_count_contrast_bar(12)
  led.13 <- create_count_contrast_bar(13)
  led.14 <- create_count_contrast_bar(14)
  led.15 <- create_count_contrast_bar(15)
  led.16 <- create_count_contrast_bar(16)
  led.17 <- create_count_contrast_bar(17)
  led.18 <- create_count_contrast_bar(18)

  grid.arrange(cori.1, cori.2, cori.3, ncol=2)
  grid.arrange(forss.4, forss.5, forss.6, forss.7, ncol=2)
  grid.arrange(hench.8, hench.9, hench.10, hench.11, ncol=2)
  grid.arrange(led.12, led.13, led.14, led.15, led.16, led.17, led.18, ncol=3)
}

print_prop_contrasts <- function(abs){
  cori.1 <- create_prop_contrast_bar(1, abs)
  cori.2 <- create_prop_contrast_bar(2, abs)
  cori.3 <- create_prop_contrast_bar(3, abs)
  forss.4 <- create_prop_contrast_bar(4, abs)
  forss.5 <- create_prop_contrast_bar(5, abs)
  forss.6 <- create_prop_contrast_bar(6, abs)
  forss.7 <- create_prop_contrast_bar(7, abs)
  hench.8 <- create_prop_contrast_bar(8, abs)
  hench.9 <- create_prop_contrast_bar(9, abs)
  hench.10 <- create_prop_contrast_bar(10, abs)
  hench.11 <- create_prop_contrast_bar(11, abs)
  led.12 <- create_prop_contrast_bar(12, abs)
  led.13 <- create_prop_contrast_bar(13, abs)
  led.14 <- create_prop_contrast_bar(14, abs)
  led.15 <- create_prop_contrast_bar(15, abs)
  led.16 <- create_prop_contrast_bar(16, abs)
  led.17 <- create_prop_contrast_bar(17, abs)
  led.18 <- create_prop_contrast_bar(18, abs)

  grid.arrange(cori.1, cori.2, cori.3, ncol=2)
  grid.arrange(forss.4, forss.5, forss.6, forss.7, ncol=2)
  grid.arrange(hench.8, hench.9, hench.10, hench.11, ncol=2)
  grid.arrange(led.12, led.13, led.14, led.15, led.16, led.17, led.18, ncol=3)
  #grid.arrange(cori.1, cori.2, cori.3, forss.4, forss.5, forss.6, forss.7, hench.8, hench.9, hench.10, hench.11, led.12, led.13, led.14, led.15, led.16, led.17, led.18, ncol=2)
}

#print_count_contrasts()

print_prop_contrasts(1) #Absolute differences
print_prop_contrasts(0) #Direct differences

```
